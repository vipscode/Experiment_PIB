name: Run PIB Scraper

on:
  # Manual trigger
  workflow_dispatch:
  # Schedule to run daily at 00:00 UTC (uncomment when ready)
  # schedule:
  #   - cron: '0 0 * * *'

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas
        
    - name: Run PIB scraper
      run: |
        python pib_scraper.py
        # Create directories if they don't exist (in case script fails before creating them)
        mkdir -p data/raw data/processed
        # Create empty log file if it doesn't exist
        touch pib_scraper.log
        # List directory contents for debugging
        echo "Directory structure:"
        find . -type d | sort
        echo "Files created:"
        find . -type f -name "*.csv" -o -name "*.log" | sort
        
    - name: Upload scraped data
      uses: actions/upload-artifact@v2
      with:
        name: pib-scraped-data
        path: |
          ./data/raw/
          ./data/processed/
          ./pib_scraper.log
        if-no-files-found: warn
